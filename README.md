{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q Navigation Project in Unity\n",
    "\n",
    "Solving a simulation task of collecting bananas using a vanilla DQN agent\n",
    "\n",
    "## Environment Details\n",
    "The objective of the Unity simulation is to collect as many yellow bananas as possible while avoiding the blue bananas. \n",
    "The following is the environment where the agent performs its task. \n",
    "\n",
    "```\n",
    "Unity Academy name: Academy  \n",
    "Number of Brains: 1  \n",
    "Number of External Brains : 1  \n",
    "Lesson number : 0  \n",
    "Reset Parameters :\n",
    "\n",
    "Unity brain name: BananaBrain  \n",
    "Number of Visual Observations (per agent): 0  \n",
    "Vector Observation space type: continuous  \n",
    "Vector Observation space size (per agent): 37  \n",
    "Number of stacked Vector Observation: 1  \n",
    "Vector Action space type: discrete  \n",
    "Vector Action space size (per agent): 4  \n",
    "Vector Action descriptions: , , , \n",
    "\n",
    "```\n",
    "\n",
    "The environment has 37 state spaces for the agent to operate in. There are 4 discrete actions spaces for forward, backward, turn left, turn right moves. The agent's problem is considered solved when average score of 13 is attained. The agent aim to achieve within 1800 episodes. \n",
    "\n",
    "## Installation Instruction\n",
    "\n",
    "Python 3.6 is required. The program requires PyTorch, the ML-Agents toolkit, and a few more Python packages required to complete the project.\n",
    "\n",
    "```\n",
    "git clone https://github.com/udacity/deep-reinforcement-learning.git  \n",
    "cd deep-reinforcement-learning/python  \n",
    "pip install .\n",
    "```\n",
    "\n",
    "Run the following to create drlnd kernel in ipython so that the right unity environment is loaded correctly  \n",
    "\n",
    "\n",
    "```python -m ipykernel install --user --name drlnd --display-name \"drlnd\"```\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Place <mark>report.ipynb</mark> in the folder <mark>p1_navigation/</mark> together with the following two files:\n",
    "\n",
    "1. dqn_agent.py - contains the DQN agent code. \n",
    "2. model.py - contains neural network class for used as Q function\n",
    "\n",
    "The Unity Banana collection environment can be downloaded from here: \n",
    "\n",
    "Linux: [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P1/Banana/Banana_Linux.zip)  \n",
    "Mac OSX: [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P1/Banana/Banana.app.zip)  \n",
    "Windows (32-bit): [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P1/Banana/Banana_Windows_x86.zip)  \n",
    "Windows (64-bit): [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P1/Banana/Banana_Windows_x86_64.zip)  \n",
    "\n",
    "Choose the environment suitable for your machine. Unzipping will create another Banana_xxxx folder. For example, if the Linux Banana environment is downloaded, ```Banana_Linux``` will be created. \n",
    "\n",
    "Run ```p1_navigation/report.ipynb```\n",
    "\n",
    "Enter the right path for the Unity Banan environment in report.ipynb. For example for a 64-bit Linux machine: \n",
    "\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"../Banana_Linux/Banana.x86_64\")\n",
    "\n",
    "```\n",
    "\n",
    "Run the remaining cell as ordered in ```report.ipynb``` to train the DQN agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
